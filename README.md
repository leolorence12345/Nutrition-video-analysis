# Food Tracking and Analysis System

A comprehensive food detection, tracking, and nutrition analysis system using multiple AI models including Gemini, YOLO-World, Grounding DINO, SAM2, and more.

## ðŸŽ¥ Video Preview

<div align="center">

### Watch the Demo Video

[![Food Tracking Demo Video](https://img.shields.io/badge/â–¶ï¸-Watch%20Video%20Demo-red?style=for-the-badge)](./smart_tracked_WhatsApp%20Video%202025-09-10%20at%2005.16.56_9874c762.mp4)

**ðŸ“¹ [Click here to view/download the tracking video](./smart_tracked_WhatsApp%20Video%202025-09-10%20at%2005.16.56_9874c762.mp4)**

> **Note**: Click the link above to view the video. GitHub will display it as a downloadable file that you can play in your browser or download.

**What this video demonstrates:**
- âœ… Food item detection and tracking with continuous IDs
- âœ… Segmentation masks for each tracked item  
- âœ… Frame-by-frame object persistence
- âœ… Real-time visualization of tracking results

</div>

## Live Production API

**GitHub**: https://github.com/leolorence12345/-nutrition-video-analysis  
**Live Demo**: http://18.214.98.110:8000  
**API Docs**: http://18.214.98.110:8000/docs  
**Health Check**: http://18.214.98.110:8000/health

**Production Deployment**: AWS EC2 (t3.xlarge)

## Features

- **Multi-Model Detection**: Support for Gemini, YOLO-World, Grounding DINO, OWL-ViT, Detectron2, and YOLOE
- **Video Tracking**: DeepSORT, ByteTrack, and SAM2-based tracking systems with continuous object IDs
- **Segmentation**: SAM, SAM2, and CLIP-based segmentation methods
- **Live Visualization**: Real-time tracking and detection visualization tools
- **Production API**: FastAPI-based REST API for video analysis (see `deploy/` directory)
- **3D Analysis**: Metric3D integration for depth and volume estimation
- **Nutrition Database**: RAG system with FNDDS and CoFID databases
- **Model Fine-tuning**: Scripts for fine-tuning Grounding DINO on custom food datasets

## Quick Start

### Setup Environment

```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Set Gemini API key (required for Gemini-based demos)
export GEMINI_API_KEY='your_api_key_here'  # Linux/Mac
$env:GEMINI_API_KEY="your_api_key_here"   # Windows PowerShell
```

### Run Demos

```bash
# Simple food analysis demo
python demos/simple_demo.py

# Video analysis demo
python demos/video_demo.py

# Visualize existing results
python demos/view_visualizations.py

# Compare different detection models
python demos/compare_all_models.py

# Test specific detection methods
python demos/gemini_bbox_detection.py
python demos/grounding_dino_detection.py
python demos/yolo_world_detection.py
python demos/yoloe_detection.py
```

### Core Systems

#### Video Food Analysis System
```bash
# Main video analysis pipeline combining SAM segmentation + tracking + Gemini labeling
python core/video_food_analysis_system.py
```

#### Tracking Systems
- **Gemini-based tracking**: `core/gemini_object_detection_tracking.py`, `core/gemini_segmentation_tracking.py`
- **DeepSORT tracking**: `core/final_deepsort_system.py`, `core/proper_deepsort_tracking.py`
- **ByteTrack integration**: `core/bytetrack_gemini_integration.py`
- **Working systems**: `core/working_gemini_detection_tracking.py`, `core/working_tracking_system.py`

#### Live Visualization
```bash
# Real-time visualization tools
python core/live_bytetrack_visualization.py
python core/live_opencv_visualization.py
python core/live_segmentation_visualization.py
```

#### Model Testing
```bash
# Test various detection models
python scripts/test_owlvit_detection.py
python scripts/test_detectron2_clip.py
python scripts/test_sam_clip.py
python scripts/test_maskrcnn_clip.py
python scripts/test_open_food_detection.py
```

### Production API

The project includes a production-ready API in `deploy/`:

```bash
cd deploy
# See deploy/README.md for full deployment instructions
python run_local.py
```

**Live API**: http://18.214.98.110:8000/docs

## Project Structure

```
Nutrition5k/
â”œâ”€â”€ core/                           # Core tracking and analysis systems
â”‚   â”œâ”€â”€ video_food_analysis_system.py      # Main video analysis pipeline
â”‚   â”œâ”€â”€ gemini_object_detection_tracking.py
â”‚   â”œâ”€â”€ gemini_segmentation_tracking.py
â”‚   â”œâ”€â”€ simple_gemini_tracking.py
â”‚   â”œâ”€â”€ simple_gemini_segmentation.py
â”‚   â”œâ”€â”€ final_deepsort_system.py
â”‚   â”œâ”€â”€ proper_deepsort_tracking.py
â”‚   â”œâ”€â”€ bytetrack_gemini_integration.py
â”‚   â”œâ”€â”€ working_gemini_detection_tracking.py
â”‚   â”œâ”€â”€ working_tracking_system.py
â”‚   â”œâ”€â”€ live_bytetrack_visualization.py
â”‚   â”œâ”€â”€ live_opencv_visualization.py
â”‚   â””â”€â”€ live_segmentation_visualization.py
â”œâ”€â”€ demos/                          # Demo scripts and examples
â”‚   â”œâ”€â”€ simple_demo.py
â”‚   â”œâ”€â”€ video_demo.py
â”‚   â”œâ”€â”€ compare_all_models.py
â”‚   â”œâ”€â”€ comprehensive_model_comparison.py
â”‚   â”œâ”€â”€ gemini_bbox_detection.py
â”‚   â”œâ”€â”€ gemini_2_bbox_detection.py
â”‚   â”œâ”€â”€ grounding_dino_detection.py
â”‚   â”œâ”€â”€ grounding_dino_hf_detection.py
â”‚   â”œâ”€â”€ grounding_dino_multi_prompt.py
â”‚   â”œâ”€â”€ yolo_world_detection.py
â”‚   â”œâ”€â”€ yolo_world_enhanced.py
â”‚   â”œâ”€â”€ yoloe_detection.py
â”‚   â”œâ”€â”€ yoloe_prompt_free.py
â”‚   â”œâ”€â”€ live_bbox_detection.py
â”‚   â”œâ”€â”€ live_bbox_with_save.py
â”‚   â”œâ”€â”€ view_visualizations.py
â”‚   â”œâ”€â”€ view_analysis_video.py
â”‚   â””â”€â”€ visualize_results.py
â”œâ”€â”€ scripts/                        # Utility scripts
â”‚   â”œâ”€â”€ compute_eval_statistics.py
â”‚   â”œâ”€â”€ generate_dataset_with_gemini.py
â”‚   â”œâ”€â”€ generate_grounding_dino_dataset.py
â”‚   â”œâ”€â”€ finetune_grounding_dino.py
â”‚   â”œâ”€â”€ finetune_grounding_dino_simple.py
â”‚   â”œâ”€â”€ finetune_grounding_dino_qlora.py
â”‚   â”œâ”€â”€ test_owlvit_detection.py
â”‚   â”œâ”€â”€ test_detectron2_clip.py
â”‚   â”œâ”€â”€ test_sam_clip.py
â”‚   â”œâ”€â”€ test_maskrcnn_clip.py
â”‚   â”œâ”€â”€ test_open_food_detection.py
â”‚   â”œâ”€â”€ extract_frames.sh
â”‚   â””â”€â”€ extract_frames_sampled.sh
â”œâ”€â”€ deploy/                         # Production API deployment
â”‚   â”œâ”€â”€ app/                        # FastAPI application
â”‚   â”œâ”€â”€ README.md                   # Deployment guide
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ Grounded-SAM-2/                 # Grounded SAM-2 implementation
â”‚   â”œâ”€â”€ deploy/                     # Alternative deployment location
â”‚   â”œâ”€â”€ sam2/                       # SAM2 model implementation
â”‚   â”œâ”€â”€ grounding_dino/             # Grounding DINO implementation
â”‚   â””â”€â”€ nutrition_rag_system.py      # RAG system for nutrition data
â”œâ”€â”€ analysis/                       # Analysis and comparison documents
â”‚   â”œâ”€â”€ methods_comparison.md
â”‚   â”œâ”€â”€ video_processing_cost_analysis.md
â”‚   â”œâ”€â”€ gemini_production_cost_analysis.md
â”‚   â””â”€â”€ gemini_2.5_flash_3d_volume_estimation.md
â”œâ”€â”€ models/                         # Pre-trained model files
â”‚   â”œâ”€â”€ cache/
â”‚   â”œâ”€â”€ grounding_dino_finetuned/
â”‚   â””â”€â”€ sam_vit_*.pth
â”œâ”€â”€ data/                           # Dataset files and results
â”‚   â”œâ”€â”€ food_videos_dataset/        # Food video dataset
â”‚   â”œâ”€â”€ food101_local/              # Food-101 dataset
â”‚   â”œâ”€â”€ gemini_food_dataset/        # Gemini-generated annotations
â”‚   â”œâ”€â”€ food_videos_tracking_results/
â”‚   â”œâ”€â”€ metric3d_results/
â”‚   â””â”€â”€ *_results/                  # Various model results
â”œâ”€â”€ results/                        # Output results and visualizations
â”œâ”€â”€ videos/                         # Video files for analysis
â”œâ”€â”€ res/                            # Resources and sample images
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ download_food_dataset.py        # Dataset download utility
â”œâ”€â”€ WHY_DETECTIONS_ARE_WRONG.md     # Model limitations analysis
â””â”€â”€ README.md                       # This file
```

## Additional Video Results

More tracking results are available in:
- `videos/` - Sample input videos
- `data/food_videos_tracking_results/` - Processed tracking videos
- `data/metric3d_results/` - Videos with depth and volume estimation

## Supported Models

### Detection Models
- **Gemini API**: Google's Gemini for food detection and labeling
- **YOLO-World**: Open-vocabulary object detection
- **YOLOE**: YOLO with enhanced capabilities
- **Grounding DINO**: Open-set object detection
- **OWL-ViT**: Open-vocabulary vision transformer
- **Detectron2**: Facebook's detection framework
- **Mask R-CNN**: Instance segmentation

### Tracking Models
- **DeepSORT**: Multi-object tracking
- **ByteTrack**: High-performance tracking
- **SAM2**: Segment Anything Model 2 for video tracking

### Segmentation Models
- **SAM**: Segment Anything Model
- **SAM2**: Video segmentation
- **CLIP**: Zero-shot segmentation

## Research & Analysis

The project includes comprehensive analysis documents:

- **Methods Comparison** (`analysis/methods_comparison.md`): Detailed comparison of different detection and segmentation approaches
- **Cost Analysis** (`analysis/video_processing_cost_analysis.md`, `analysis/gemini_production_cost_analysis.md`): API cost analysis for Gemini and video processing
- **3D Volume Estimation** (`analysis/gemini_2.5_flash_3d_volume_estimation.md`): Analysis of depth and volume estimation methods
- **Model Limitations** (`WHY_DETECTIONS_ARE_WRONG.md`): Insights into model limitations and solutions

## Download Food Dataset

The repository includes a utility to download food video datasets:

```bash
python download_food_dataset.py
```

This downloads the food videos dataset from Kaggle for testing and development.

## Dependencies

Key dependencies include:
- `google-genai` - Gemini API client
- `opencv-python` - Computer vision operations
- `transformers` - Hugging Face transformers for Grounding DINO
- `torch`, `torchvision` - PyTorch for deep learning
- `ultralytics` - YOLO models
- `matplotlib` - Visualization
- `numpy` - Numerical operations

See `requirements.txt` for the complete list.

## License

This project extends food tracking and analysis capabilities. The Nutrition5k dataset (if used) is released under the Creative Commons V4.0 license.
